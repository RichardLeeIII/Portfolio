{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87195b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3aefef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  1  2  3  4  5]\n",
      " [ 0  0  0  0  6  2  7  8  4  5]\n",
      " [ 0  0  0  9 10  2  7 11  4  5]\n",
      " [ 0  0  0 12 13 14  2 15  4  5]\n",
      " [ 0  0  0 16  2 17 18 19  4  5]\n",
      " [ 0  9 20  2 21 22 23 24 25  5]\n",
      " [ 0  0  0  6 13 26  2 27  4  5]\n",
      " [ 1 13 28  2  7 29 30 31 25  5]\n",
      " [ 0  0  0 32 13 33  2 27  4  5]\n",
      " [ 0  0  9 34  2 35 36 37 38  5]\n",
      " [ 0  0  0  0  0  1  2 39  4  5]\n",
      " [ 0  0  0 16  2 40 18 41  4  5]\n",
      " [ 0  0  0  9 42  2 43 44 25  5]\n",
      " [ 0  0 45 46 13 47  2 48  4  5]\n",
      " [ 0  0  0  1 13 49  2 50  4  5]\n",
      " [ 0  0  0 16 13 51  2 52  4  5]\n",
      " [ 0  0  9 53  2 54 55 56 38  5]\n",
      " [ 0  0 57 58 13 59  2 60  4  5]\n",
      " [ 0  0  0  6 13 51  2 61  4  5]\n",
      " [ 0  1 13 62 63 64 65 56 38  5]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Positive Sentences\n",
    "positive_sentences = [\n",
    "    '私は幸せです。',\n",
    "    '彼女はとても親切です。',\n",
    "    'この本はとても面白いです。',\n",
    "    '日本の食べ物は美味しいです。',\n",
    "    '彼は優秀な学生です。',\n",
    "    'この町は美しい景色があります。',\n",
    "    '彼女の笑顔は素晴らしいです。',\n",
    "    '私の家族はとても支えてくれます。',\n",
    "    'あなたの努力は素晴らしいです。',\n",
    "    'この映画は感動的でした。'\n",
    "]\n",
    "\n",
    "# Negative Sentences\n",
    "negative_sentences = [\n",
    "    '私は悲しいです。',\n",
    "    '彼は無礼な人です。',\n",
    "    'このテストは難しすぎます。',\n",
    "    'その店のサービスは最悪です。',\n",
    "    '私の仕事はつまらないです。',\n",
    "    '彼の態度は腹立たしいです。',\n",
    "    'このプロジェクトは失敗しました。',\n",
    "    'あのレストランの料理はまずいです。',\n",
    "    '彼女の態度は不快です。',\n",
    "    '私の財布を失くしました。'\n",
    "]\n",
    "\n",
    "# Combine sentences\n",
    "sentences = positive_sentences + negative_sentences\n",
    "\n",
    "# Labels (1 for positive, 0 for negative)\n",
    "labels = [1] * len(positive_sentences) + [0] * len(negative_sentences)\n",
    "\n",
    "# Tokenization using Janome\n",
    "tokenizer = Tokenizer()\n",
    "tokenized_sentences = [tokenizer.tokenize(sentence, wakati=True) for sentence in sentences]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Sentences': tokenized_sentences, 'Label': labels})\n",
    "\n",
    "# Vectorization\n",
    "word_index = {}\n",
    "sequences = []\n",
    "index = 1\n",
    "for sentence_tokens in tokenized_sentences:\n",
    "    sequence = []\n",
    "    for token in sentence_tokens:\n",
    "        if token not in word_index:\n",
    "            word_index[token] = index\n",
    "            index += 1\n",
    "        sequence.append(word_index[token])\n",
    "    sequences.append(sequence)\n",
    "\n",
    "# Padding sequences\n",
    "max_length = max(len(sequence) for sequence in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Print the vectorized data\n",
    "print(padded_sequences)\n",
    "print(labels)\n",
    "\n",
    "# Reflect here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3739ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  3  4  5]\n",
      " [ 0  0  0 ...  8  4  5]\n",
      " [ 0  0  0 ... 11  4  5]\n",
      " ...\n",
      " [ 0  0  0 ... 60  4  5]\n",
      " [ 0  0  0 ... 61  4  5]\n",
      " [ 0  0  0 ... 56 38  5]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Padding sequences with max length of 100\n",
    "max_length = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Print the vectorized data\n",
    "print(padded_sequences)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5725f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(padded_sequences)\n",
    "labels = np.array(labels)\n",
    "\n",
    "train_x = input_data[5:]\n",
    "train_y = labels[5:]\n",
    "test_x = input_data[:5]\n",
    "test_y = labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b63aab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c526e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,201\n",
      "Trainable params: 10,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1066 - accuracy: 0.4667 - val_loss: 0.7630 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1579 - accuracy: 0.6000 - val_loss: 0.8289 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4367 - accuracy: 0.4667 - val_loss: 0.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.8815 - accuracy: 0.6000 - val_loss: 0.8754 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0510 - accuracy: 0.5333 - val_loss: 0.8856 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9180 - accuracy: 0.5333 - val_loss: 0.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6936 - accuracy: 0.6000 - val_loss: 0.9230 - val_accuracy: 0.0000e+00\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, callbacks\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation=\"relu\", input_shape=(100,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = callbacks.EarlyStopping(monitor='accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "results = model.fit(train_x, train_y, epochs=100, batch_size=32, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebbdb918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9230 - accuracy: 0.0000e+00\n",
      "Loss: 0.9230367541313171\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ccd1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c319c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,201\n",
      "Trainable params: 10,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dense_12\n",
      "[array([[-0.19104515, -0.14723592,  0.16701202, ...,  0.00328818,\n",
      "        -0.1625936 ,  0.19081573],\n",
      "       [ 0.12444593, -0.13415161, -0.03990316, ...,  0.09343542,\n",
      "        -0.06623515,  0.12483655],\n",
      "       [-0.16410594, -0.18608657,  0.19197349, ...,  0.11322398,\n",
      "        -0.14363661, -0.16826788],\n",
      "       ...,\n",
      "       [-0.0836646 ,  0.04093689,  0.05313778, ...,  0.0667721 ,\n",
      "        -0.09319091,  0.19031233],\n",
      "       [-0.10152125, -0.13228865, -0.15418726, ..., -0.1083558 ,\n",
      "        -0.09818721, -0.02457031],\n",
      "       [ 0.0567974 , -0.16357553,  0.18944497, ...,  0.08630355,\n",
      "         0.03398227, -0.12864329]], dtype=float32), array([-2.9637802e-03,  5.6724166e-03,  2.2109146e-03, -1.9920287e-03,\n",
      "        5.3504184e-03,  0.0000000e+00,  1.4629421e-03,  3.9990558e-03,\n",
      "       -6.7270622e-03,  1.7101100e-03, -5.9354589e-03, -4.7983075e-03,\n",
      "       -2.5078959e-03, -5.7163578e-04,  4.1843299e-03,  1.5052952e-03,\n",
      "       -5.0413655e-03, -3.5794871e-03, -2.9125286e-03,  0.0000000e+00,\n",
      "       -6.4376122e-03,  0.0000000e+00,  6.2430315e-03, -4.9585442e-04,\n",
      "        3.3545045e-03,  0.0000000e+00,  2.0828184e-03,  4.9585793e-03,\n",
      "        1.1399284e-03,  2.2089906e-04, -2.8717297e-03,  5.3804256e-03,\n",
      "        2.1243310e-03, -3.7209170e-03,  1.5462462e-03,  5.6789099e-04,\n",
      "        0.0000000e+00,  2.2344778e-03, -3.6880039e-03, -3.8870682e-03,\n",
      "        5.4077045e-03, -5.1950631e-03, -4.3533104e-03,  5.3851116e-03,\n",
      "       -8.0919848e-04, -5.5615879e-03, -5.4771411e-03,  2.5389858e-03,\n",
      "        1.1297350e-05, -3.1316618e-03], dtype=float32)]\n",
      "dropout_6\n",
      "[]\n",
      "dense_13\n",
      "[array([[-0.18811561, -0.03369164, -0.20569168, ..., -0.1484222 ,\n",
      "        -0.0050512 ,  0.06299356],\n",
      "       [-0.22229107, -0.01957338,  0.12436817, ...,  0.03464125,\n",
      "         0.24043982,  0.06595287],\n",
      "       [ 0.14527923, -0.12353937, -0.0590113 , ..., -0.18338141,\n",
      "        -0.14742893, -0.09821766],\n",
      "       ...,\n",
      "       [ 0.18320318, -0.16091155,  0.15505448, ..., -0.14250767,\n",
      "         0.22594506, -0.24386322],\n",
      "       [-0.02488485, -0.05039408, -0.13688976, ..., -0.10160307,\n",
      "        -0.03089397, -0.0906227 ],\n",
      "       [ 0.21506844, -0.16721787, -0.04636728, ...,  0.15160717,\n",
      "        -0.13362944,  0.19364962]], dtype=float32), array([-0.00227484, -0.00613957, -0.00260722, -0.0020578 ,  0.0042239 ,\n",
      "       -0.00084793, -0.00097793, -0.00282904, -0.00326164, -0.00209773,\n",
      "       -0.00193573,  0.00274722, -0.00086672, -0.00595942,  0.00620855,\n",
      "        0.00028388, -0.00394801,  0.00357988,  0.00229966,  0.00411202,\n",
      "       -0.00480884,  0.00025269, -0.00149196, -0.00152017, -0.00110686,\n",
      "       -0.00379681, -0.00086555,  0.00404709,  0.0039359 , -0.00447771,\n",
      "        0.00188827,  0.00093164, -0.00498994, -0.00610349,  0.00132982,\n",
      "       -0.00322352, -0.00271467, -0.00076367, -0.00339794, -0.00501801,\n",
      "       -0.00329896, -0.00499982,  0.00341209, -0.00014099,  0.00324783,\n",
      "        0.00096281,  0.00156687, -0.006184  ,  0.00605047,  0.00394299],\n",
      "      dtype=float32)]\n",
      "dropout_7\n",
      "[]\n",
      "dense_14\n",
      "[array([[-0.19850317,  0.14601383, -0.13060878, ...,  0.08483662,\n",
      "        -0.18304484, -0.19534509],\n",
      "       [ 0.2015577 , -0.11324158,  0.08619135, ...,  0.04467693,\n",
      "         0.03640533, -0.1995869 ],\n",
      "       [ 0.14365666, -0.02082996, -0.22723094, ...,  0.03397933,\n",
      "         0.18146291, -0.1648822 ],\n",
      "       ...,\n",
      "       [-0.2485639 ,  0.07489257,  0.12747261, ...,  0.21273541,\n",
      "        -0.03090007, -0.0476419 ],\n",
      "       [-0.06912465,  0.16413067, -0.09203527, ...,  0.0442575 ,\n",
      "         0.22024915,  0.09153796],\n",
      "       [-0.03160242, -0.17390223, -0.12202878, ...,  0.13947567,\n",
      "         0.13289371, -0.04611753]], dtype=float32), array([-5.8182995e-03,  3.2871638e-03,  2.3006645e-03, -4.1443398e-03,\n",
      "        3.5700342e-03,  3.8824249e-03,  2.0546584e-04,  8.2807767e-04,\n",
      "       -1.4121225e-04,  8.5274404e-04, -6.6155510e-04,  2.8866194e-03,\n",
      "       -3.7748844e-03, -5.1425677e-03,  3.4565496e-04, -4.6859006e-04,\n",
      "        3.1099753e-03, -3.0290254e-03,  1.3805014e-03, -2.1971967e-03,\n",
      "       -5.4939874e-03, -3.5007484e-03, -1.8356494e-03,  2.1787549e-03,\n",
      "       -5.7324516e-03, -4.9887225e-03, -3.9131502e-03, -3.5756247e-04,\n",
      "        1.2957848e-03, -5.7884674e-03,  3.6096310e-03, -3.8929333e-03,\n",
      "       -3.7229075e-03,  1.9824147e-05,  2.3145541e-03,  3.9997445e-03,\n",
      "       -3.2307866e-03,  1.5199753e-03, -2.0486922e-03,  1.8095900e-03,\n",
      "       -5.7543168e-04, -3.4841495e-03, -1.1042184e-03,  7.2728680e-04,\n",
      "       -6.0615190e-03,  4.1083279e-03, -5.4684454e-03, -4.4317888e-03,\n",
      "        1.3297159e-04, -9.3656010e-04], dtype=float32)]\n",
      "dense_15\n",
      "[array([[-0.24130934],\n",
      "       [-0.25247416],\n",
      "       [ 0.31730363],\n",
      "       [ 0.15147412],\n",
      "       [-0.04560475],\n",
      "       [-0.3054778 ],\n",
      "       [-0.13877162],\n",
      "       [ 0.13509528],\n",
      "       [-0.31646082],\n",
      "       [-0.20656782],\n",
      "       [-0.02947602],\n",
      "       [ 0.1128431 ],\n",
      "       [-0.31093237],\n",
      "       [ 0.08143434],\n",
      "       [-0.27108622],\n",
      "       [-0.12305736],\n",
      "       [-0.11939759],\n",
      "       [ 0.10873512],\n",
      "       [ 0.10105529],\n",
      "       [-0.20923257],\n",
      "       [ 0.0856396 ],\n",
      "       [ 0.24220419],\n",
      "       [-0.33463627],\n",
      "       [-0.23388098],\n",
      "       [ 0.32538053],\n",
      "       [-0.18942918],\n",
      "       [ 0.00172648],\n",
      "       [-0.27007812],\n",
      "       [ 0.04600565],\n",
      "       [ 0.12339332],\n",
      "       [-0.22816606],\n",
      "       [-0.07829814],\n",
      "       [ 0.26613963],\n",
      "       [-0.1468706 ],\n",
      "       [-0.0313178 ],\n",
      "       [-0.10694759],\n",
      "       [-0.08680391],\n",
      "       [ 0.01431287],\n",
      "       [ 0.3113076 ],\n",
      "       [ 0.20056312],\n",
      "       [ 0.14771865],\n",
      "       [ 0.27922362],\n",
      "       [-0.245665  ],\n",
      "       [-0.16193266],\n",
      "       [ 0.23192722],\n",
      "       [-0.10702783],\n",
      "       [ 0.32821953],\n",
      "       [ 0.22374481],\n",
      "       [-0.2586371 ],\n",
      "       [ 0.12002337]], dtype=float32), array([-0.0034914], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('model.hdf5')\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Access the layers and their weights\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "    print(layer.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "325b4616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n",
      "Sentence:  あなたの日本語の文章をここに入力してください。\n",
      "Sentiment:  Negative\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "\n",
    "# Random Japanese sentence\n",
    "sentence = \"あなたの日本語の文章をここに入力してください。\"\n",
    "\n",
    "# Tokenization using Janome\n",
    "tokenizer = Tokenizer()\n",
    "tokens = tokenizer.tokenize(sentence, wakati=True)\n",
    "\n",
    "# Convert tokens to indices based on the word_index\n",
    "input_sequence = [word_index.get(token, 0) for token in tokens]\n",
    "\n",
    "# Pad the sequence\n",
    "max_length = 100  # Set the maximum sequence length used during training\n",
    "padded_sequence = pad_sequences([input_sequence], maxlen=max_length)\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('model.hdf5')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "# Interpret the predictions\n",
    "if predictions[0] > 0.5:\n",
    "    sentiment = \"Positive\"\n",
    "else:\n",
    "    sentiment = \"Negative\"\n",
    "\n",
    "print(\"Sentence: \", sentence)\n",
    "print(\"Sentiment: \", sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences to tokenized sequences\n",
    "tokenized_sequences = []\n",
    "for sentence in df['Sentence']:\n",
    "    sentence_tokens = tokenizer.tokenize(sentence, wakati=True)\n",
    "    sequence = [word_index.get(token, 0) for token in sentence_tokens]\n",
    "    tokenized_sequences.append(sequence)\n",
    "\n",
    "# Pad sequences\n",
    "padded_sequences = pad_sequences(tokenized_sequences, maxlen=max_length)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(padded_sequences)\n",
    "\n",
    "# Interpret the predictions\n",
    "sentiments = []\n",
    "for prediction in predictions:\n",
    "    if prediction > 0.5:\n",
    "        sentiment = \"Positive\"\n",
    "    else:\n",
    "        sentiment = \"Negative\"\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Add predicted sentiments to the DataFrame\n",
    "df['Predicted Sentiment'] = sentiments\n",
    "\n",
    "# Print the DataFrame with predicted sentiments\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
